{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arshadulhoque/aes-2-submission?scriptVersionId=181496240\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AdamW\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\ndata","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/trained-deberta-model\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/trained-deberta-model\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the test data\ntest_encodings = tokenizer(list(test_data['full_text']), truncation=True, padding=True, max_length=1024, return_tensors='pt')\n\n# Create DataLoader for test set\ntest_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'])\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation on the test set\nmodel.eval()\ntest_preds = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask = batch\n        input_ids = input_ids.to(device, dtype=torch.long)  # Ensure inputs are of type torch.long\n        attention_mask = attention_mask.to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        preds = logits.argmax(dim=1).cpu().numpy()\n        test_preds.extend(preds)\n\n# Adjust the predictions back to the original score range (1-6)\ntest_preds = [pred + 1 for pred in test_preds]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the predictions in the required format\nsubmission_df = pd.DataFrame({'essay_id': test_data['essay_id'], 'score': test_preds})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}