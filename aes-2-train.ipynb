{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments, AdamW, AutoModelForSequenceClassification, DataCollatorWithPadding, AddedToken","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove essay_id column\ndata.drop('essay_id', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import nltk\n# from nltk.corpus import stopwords\n# from nltk.tokenize import word_tokenize\n# from nltk.stem import WordNetLemmatizer\n\n# nltk.download('stopwords')\n# nltk.download('punkt')\n# nltk.download('wordnet')\n\n# lemmatizer = WordNetLemmatizer()\n# stop_words = set(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import zipfile\n\n# # Unzip wordnet.zip\n# zip_file_path = '/usr/share/nltk_data/corpora/wordnet.zip'\n# extract_to_path = '/usr/share/nltk_data/corpora/'\n\n# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n#     zip_ref.extractall(extract_to_path)\n\n# print(\"Unzipping completed successfully.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def preprocess_text(text):\n#     tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n#     tokens = [token for token in tokens if token.isalpha() and token not in stop_words]  # Filter out non-alphabetic tokens and stopwords\n#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize tokens\n#     return ' '.join(lemmatized_tokens)\n\n# # Apply preprocessing to the 'full_text' column\n# data['full_text'] = data['full_text'].apply(preprocess_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\ntokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel\nmodel = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-large\",num_labels=6)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the data\ndef tokenize_data(text_list):\n    return tokenizer(text_list, truncation=True, padding=True, max_length=1024, return_tensors='pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training and testing sets\ntrain_texts, test_texts, y_train, y_test = train_test_split(data['full_text'], data['score'], test_size=0.2, random_state=42, stratify = data.score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize the texts\ntrain_encodings = tokenize_data(train_texts.tolist())\ntest_encodings = tokenize_data(test_texts.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify and adjust label values\ntrain_labels = torch.tensor(y_train.values)\ntest_labels = torch.tensor(y_test.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If labels are out of range, apply necessary adjustments (if needed)\nnum_labels = 6\ntrain_labels = torch.clamp(train_labels, 0, num_labels - 1)\ntest_labels = torch.clamp(test_labels, 0, num_labels - 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Dataset objects\ntrain_dataset = CustomDataset(train_encodings, train_labels)\ntest_dataset = CustomDataset(test_encodings, test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Trainer class for OLL\nclass OLL2Trainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        num_classes = model.config.num_labels\n        dist_matrix = torch.arange(num_classes).unsqueeze(0) - torch.arange(num_classes).unsqueeze(1)\n        dist_matrix = dist_matrix ** 2  # Square distances\n        dist_matrix = dist_matrix.float().to(model.device)\n        \n        labels = inputs[\"labels\"]\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probas = F.softmax(logits, dim=1)\n        true_labels = [num_classes * [labels[k].item()] for k in range(len(labels))]\n        label_ids = len(labels) * [[k for k in range(num_classes)]]\n        distances = [[float(dist_matrix[true_labels[j][i]][label_ids[j][i]]) for i in range(num_classes)] for j in range(len(labels))]\n        distances_tensor = torch.tensor(distances, device=model.device, requires_grad=True)\n        err = -torch.log(1 - probas) * abs(distances_tensor)\n        loss = torch.sum(err, axis=1).mean()\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/trained_deberta_model',\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n    optim=\"adamw_bnb_8bit\",\n    learning_rate = 2e-5,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    logging_dir='./logs',\n    logging_steps=100,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    do_eval=True,\n    eval_steps=100,\n    save_total_limit=1,\n    save_steps = 100,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"loss\",\n    report_to=\"none\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trainer instance\ntrainer = OLL2Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate the model, logging train and validation loss\ndef train_and_evaluate(trainer):\n    for epoch in range(int(training_args.num_train_epochs)):\n        train_result = trainer.train()\n        eval_result = trainer.evaluate()\n        train_loss = train_result.training_loss\n        eval_loss = eval_result[\"eval_loss\"]\n        print(f\"Epoch {epoch + 1}: Training Loss: {train_loss}, Validation Loss: {eval_loss}\")\n\ntrain_and_evaluate(trainer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import jit\n@jit(nopython=True)\ndef cpmp_qwk(a1, a2, max_rat=3) -> float:\n    \"\"\"\n    A ultra fast implementation of Quadratic Weighted Kappa (QWK)\n    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133\n    \n    :param a1: The ground truth labels\n    :param a2: The predicted labels\n    :param max_rat: The maximum target value\n    \n    return: A floating point number with the QWK score\n    \"\"\"\n    assert(len(a1) == len(a2))\n    \n    # Convert to numpy arrays with explicit dtype\n    a1 = np.asarray(a1, dtype=np.int32)\n    a2 = np.asarray(a2, dtype=np.int32)\n\n    hist1 = np.zeros((max_rat + 1,), dtype=np.int32)\n    hist2 = np.zeros((max_rat + 1,), dtype=np.int32)\n\n    o = 0.0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o += (i - j) * (i - j)\n\n    e = 0.0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1.0 - o / e","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions on the validation set\ndef evaluate_model(trainer, eval_dataloader):\n    all_preds = []\n    all_labels = []\n    for batch in eval_dataloader:\n        batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = trainer.model(**batch)\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=-1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(batch[\"labels\"].cpu().numpy())\n    return all_labels, all_preds\n\n# Compute and print QWK score\neval_dataloader = trainer.get_eval_dataloader()\ntrue_labels, pred_labels = evaluate_model(trainer, eval_dataloader)\nqwk_score = cpmp_qwk(true_labels, pred_labels)\nprint(f\"Quadratic Weighted Kappa score: {qwk_score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained('/kaggle/working/trained_deberta_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}