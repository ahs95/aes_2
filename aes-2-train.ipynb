{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arshadulhoque/aes-2-train?scriptVersionId=181474428\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T18:28:40.012815Z","iopub.execute_input":"2024-05-29T18:28:40.013288Z","iopub.status.idle":"2024-05-29T18:28:40.022748Z","shell.execute_reply.started":"2024-05-29T18:28:40.013254Z","shell.execute_reply":"2024-05-29T18:28:40.021495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AdamW\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nfrom transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\nfrom sklearn.metrics import cohen_kappa_score, classification_report, confusion_matrix, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:40.024936Z","iopub.execute_input":"2024-05-29T18:28:40.025266Z","iopub.status.idle":"2024-05-29T18:28:40.034267Z","shell.execute_reply.started":"2024-05-29T18:28:40.025228Z","shell.execute_reply":"2024-05-29T18:28:40.033205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:40.035484Z","iopub.execute_input":"2024-05-29T18:28:40.035783Z","iopub.status.idle":"2024-05-29T18:28:40.370024Z","shell.execute_reply.started":"2024-05-29T18:28:40.035759Z","shell.execute_reply":"2024-05-29T18:28:40.369157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove essay_id column\ndata.drop('essay_id', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:40.37135Z","iopub.execute_input":"2024-05-29T18:28:40.371792Z","iopub.status.idle":"2024-05-29T18:28:40.377963Z","shell.execute_reply.started":"2024-05-29T18:28:40.37176Z","shell.execute_reply":"2024-05-29T18:28:40.377161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\ntrain_data, test_data = train_test_split(data, test_size=0.2, stratify=data['score'], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:40.380249Z","iopub.execute_input":"2024-05-29T18:28:40.380534Z","iopub.status.idle":"2024-05-29T18:28:40.3989Z","shell.execute_reply.started":"2024-05-29T18:28:40.380511Z","shell.execute_reply":"2024-05-29T18:28:40.398181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-xsmall\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:40.399985Z","iopub.execute_input":"2024-05-29T18:28:40.400307Z","iopub.status.idle":"2024-05-29T18:28:41.736009Z","shell.execute_reply.started":"2024-05-29T18:28:40.400276Z","shell.execute_reply":"2024-05-29T18:28:41.735029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoModel\nmodel = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-xsmall\", num_labels=6)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:41.73732Z","iopub.execute_input":"2024-05-29T18:28:41.737644Z","iopub.status.idle":"2024-05-29T18:28:42.041302Z","shell.execute_reply.started":"2024-05-29T18:28:41.737619Z","shell.execute_reply":"2024-05-29T18:28:42.040357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the training data\ntrain_encodings = tokenizer(list(train_data['full_text']), truncation=True, padding=True, max_length=1024, return_tensors='pt')\ntrain_labels = torch.tensor(train_data['score'].values - 1)  # Adjust labels to start from 0","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:28:42.042419Z","iopub.execute_input":"2024-05-29T18:28:42.042725Z","iopub.status.idle":"2024-05-29T18:29:04.380415Z","shell.execute_reply.started":"2024-05-29T18:28:42.042702Z","shell.execute_reply":"2024-05-29T18:29:04.379421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the testing data\ntest_encodings = tokenizer(list(test_data['full_text']), truncation=True, padding=True, max_length=1024, return_tensors='pt')\ntest_labels = torch.tensor(test_data['score'].values - 1)  # Adjust labels to start from 0","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:29:04.381623Z","iopub.execute_input":"2024-05-29T18:29:04.381883Z","iopub.status.idle":"2024-05-29T18:29:09.415489Z","shell.execute_reply.started":"2024-05-29T18:29:04.381862Z","shell.execute_reply":"2024-05-29T18:29:09.414502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training and testing sets\ntrain_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\ntest_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:29:09.416674Z","iopub.execute_input":"2024-05-29T18:29:09.41693Z","iopub.status.idle":"2024-05-29T18:29:09.422527Z","shell.execute_reply.started":"2024-05-29T18:29:09.416909Z","shell.execute_reply":"2024-05-29T18:29:09.421619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:29:09.423768Z","iopub.execute_input":"2024-05-29T18:29:09.424106Z","iopub.status.idle":"2024-05-29T18:29:09.439267Z","shell.execute_reply.started":"2024-05-29T18:29:09.424075Z","shell.execute_reply":"2024-05-29T18:29:09.438322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move model to appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.device_count() > 1:\n  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  model = nn.DataParallel(model)\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:29:09.440277Z","iopub.execute_input":"2024-05-29T18:29:09.440558Z","iopub.status.idle":"2024-05-29T18:29:09.715327Z","shell.execute_reply.started":"2024-05-29T18:29:09.440536Z","shell.execute_reply":"2024-05-29T18:29:09.714406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accumulation_steps = 4  # Accumulate gradients over 4 steps\ntotal_steps = len(train_loader) * accumulation_steps\n\nfor epoch in range(1):  # Number of epochs\n    model.train()\n    optimizer.zero_grad()\n    step = 0\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device, dtype=torch.long)  # Ensure inputs are of type torch.long\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        # Perform backpropagation for gradient accumulation\n        loss = loss / accumulation_steps\n        loss.backward()\n\n        step += 1\n        if step % accumulation_steps == 0 or step == total_steps:\n            optimizer.step()\n            optimizer.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:29:09.716426Z","iopub.execute_input":"2024-05-29T18:29:09.716708Z","iopub.status.idle":"2024-05-29T18:48:55.152727Z","shell.execute_reply.started":"2024-05-29T18:29:09.716684Z","shell.execute_reply":"2024-05-29T18:48:55.151883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation on test set\nmodel.eval()\ntest_preds = []\ntest_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device, dtype=torch.long)  # Ensure inputs are of type torch.long\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        preds = logits.argmax(dim=1).cpu().numpy()\n        test_preds.extend(preds)\n        test_labels.extend(labels.cpu().numpy())\n\n# Calculate Quadratic Weighted Kappa score\nqwk_score = cohen_kappa_score(test_labels, test_preds, weights='quadratic')\nprint(f\"Quadratic Weighted Kappa Score: {qwk_score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:48:55.155787Z","iopub.execute_input":"2024-05-29T18:48:55.156069Z","iopub.status.idle":"2024-05-29T18:50:44.785235Z","shell.execute_reply.started":"2024-05-29T18:48:55.156045Z","shell.execute_reply":"2024-05-29T18:50:44.784195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"/kaggle/working/trained_deberta_tokenizer\")\nmodel.save_pretrained(\"/kaggle/working/trained_deberta_model\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T18:50:44.786475Z","iopub.execute_input":"2024-05-29T18:50:44.786783Z","iopub.status.idle":"2024-05-29T18:50:45.447343Z","shell.execute_reply.started":"2024-05-29T18:50:44.786756Z","shell.execute_reply":"2024-05-29T18:50:45.44651Z"},"trusted":true},"execution_count":null,"outputs":[]}]}